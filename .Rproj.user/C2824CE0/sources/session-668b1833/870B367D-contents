## Vectorized Exponentiated Gradient for KLD
## sum( (y - yhat) * log(y / y_hat) )
kld <- function(y, x, tol = 1e-8, maxit = 10000, alpha = 0.1) {
  eps <- 1e-10
  p <- dim(x)[2]
  be <- rep(1/p, p)
  tx <- t(x)

  for ( iter in 1:maxit ) {
    y_hat <- pmax(x %*% be, eps)
    grad <- tx %*% (log(y_hat/y) + 1 - y/y_hat)
    be_new <- be * exp(-alpha * grad)
    be_new <- be_new / sum(be_new)
    y_hat_new <- pmax(x %*% be_new, eps)
    obj_new <- sum( (y - y_hat_new) * log(y / y_hat_new) )
    obj_old <- sum( (y - y_hat) * log(y / y_hat) )
    # If not improving, reduce step size
    if ( obj_new > obj_old ) {
      alpha <- alpha * 0.5
      next
    }
    # Check convergence
    if ( max(abs(be_new - be) ) < tol) {
      be <- be_new
      break
    }
    be <- be_new
    alpha <- min(alpha * 1.05, 0.5)  # Slowly increase step size
  }

  # Final objective
  y_hat <- pmax(x %*% be, eps)
  obj <- sum( (y - y_hat) * log(y / y_hat) )

  list( coefficients = be, value = obj, iterations = iter )
}
